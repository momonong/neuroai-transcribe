import os
import json
import glob
import shutil
from datetime import datetime
from typing import List, Dict, Optional, Any
from pathlib import Path

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

app = FastAPI()

# ==========================================
# 1. è¨­å®š & åˆå§‹åŒ– (è·¯å¾‘ä¿®æ­£æ ¸å¿ƒ)
# ==========================================

# å–å¾—ç•¶å‰æª”æ¡ˆ (backend/main.py) çš„çµ•å°è·¯å¾‘
CURRENT_FILE = os.path.abspath(__file__)
# å–å¾— backend è³‡æ–™å¤¾è·¯å¾‘
BACKEND_DIR = os.path.dirname(CURRENT_FILE)
# å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ (backend çš„ä¸Šä¸€å±¤)
PROJECT_ROOT = os.path.dirname(BACKEND_DIR)

# è¨­å®š DATA_DIR ç‚º å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ data
DATA_DIR = os.path.join(PROJECT_ROOT, "data")

# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)

print(f"ğŸš€ Server started.")
print(f"ğŸ“‚ Project Root: {PROJECT_ROOT}")
print(f"ğŸ“‚ Data Directory: {DATA_DIR}")

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ›è¼‰éœæ…‹æª”æ¡ˆ (å‰ç«¯æ’­æ”¾å½±ç‰‡ç”¨)
app.mount("/static", StaticFiles(directory=DATA_DIR), name="static")


# ==========================================
# 2. è³‡æ–™çµæ§‹ (Pydantic Models)
# ==========================================

class TranscriptSegment(BaseModel):
    sentence_id: float
    start: float
    end: float
    speaker: str
    text: str
    verification_score: float = 1.0
    status: str = "reviewed"
    needs_review: bool = False
    review_reason: Optional[str] = None

class SavePayload(BaseModel):
    filename: str  # ç›¸å°è·¯å¾‘ (CaseName/chunk_x.json)
    speaker_mapping: Dict[str, str]
    segments: List[TranscriptSegment]

# ==========================================
# 3. è¼”åŠ©å‡½å¼
# ==========================================

def get_real_path(relative_path: str):
    """å°‡å‰ç«¯å‚³ä¾†çš„ç›¸å°è·¯å¾‘è½‰æ›ç‚ºç³»çµ±çµ•å°è·¯å¾‘"""
    if ".." in relative_path:
        raise ValueError("Invalid path: '..' is not allowed")
    return os.path.join(DATA_DIR, relative_path)

# ==========================================
# 4. API å¯¦ä½œ
# ==========================================

@app.get("/api/videos")
def get_videos():
    """
    æƒææ‰€æœ‰å½±ç‰‡ï¼Œä¾›å‰ç«¯ä¸‹æ‹‰é¸å–®ä½¿ç”¨
    ä¿®æ­£ï¼šæƒæ data/CaseName/Video.mp4
    """
    video_files = []
    # æ”¯æ´å¸¸è¦‹éŸ³è¦–è¨Šæ ¼å¼
    extensions = [".mp4", ".MP4"]
    
    if not os.path.exists(DATA_DIR):
        return video_files
    
    # 1. æƒæ data è³‡æ–™å¤¾åº•ä¸‹çš„æ¯ä¸€å±¤ (Caseè³‡æ–™å¤¾)
    # ä½¿ç”¨ os.scandir æ•ˆèƒ½è¼ƒå¥½
    with os.scandir(DATA_DIR) as it:
        for entry in it:
            if entry.is_dir() and entry.name not in ["temp_chunks", "db", "text", "__pycache__"]:
                case_name = entry.name
                case_path = entry.path
                
                # 2. åœ¨è©² Case è³‡æ–™å¤¾å…§æ‰¾å½±ç‰‡
                for f in os.listdir(case_path):
                    if any(f.endswith(ext) for ext in extensions):
                        # æ’é™¤æ‰ chunk_ é–‹é ­çš„éŸ³æª”ï¼Œæˆ‘å€‘åªåˆ—å‡ºä¸»å½±ç‰‡
                        if f.startswith("chunk_"):
                            continue
                            
                        # çµ„åˆç›¸å°è·¯å¾‘
                        rel_path = f"{case_name}/{f}"
                        display_name = f"{case_name}"
                        
                        video_files.append({
                            "path": rel_path,
                            "name": display_name
                        })

    # ä¾åç¨±æ’åº
    video_files.sort(key=lambda x: x['name'], reverse=True)
    return video_files

@app.get("/api/cases")
def get_cases():
    """
    åˆ—å‡º data/ åº•ä¸‹çš„å°ˆæ¡ˆè³‡æ–™å¤¾
    """
    cases = []
    if not os.path.exists(DATA_DIR):
        return cases
    
    # å¿½ç•¥çš„ç³»çµ±è³‡æ–™å¤¾
    IGNORE_DIRS = {"temp_chunks", "db", "text", "__pycache__", "output", "test-complete-pipeline"}

    with os.scandir(DATA_DIR) as it:
        for entry in it:
            if entry.is_dir() and entry.name not in IGNORE_DIRS:
                # åªè¦ä¸æ˜¯ç³»çµ±è³‡æ–™å¤¾ï¼Œæˆ‘å€‘å°±ç•¶ä½œæ˜¯æ¡ˆä¾‹è³‡æ–™å¤¾å›å‚³
                # ä¸åšéåº¦æª¢æŸ¥ï¼Œä»¥å…å› ç‚ºæª”æ¡ˆæ ¼å¼å•é¡Œå°è‡´è³‡æ–™å¤¾æ¶ˆå¤±
                cases.append(entry.name)
    
    cases.sort(reverse=True)
    return cases

@app.get("/api/temp/chunks")
def list_chunks(case: Optional[str] = None):
    """
    åˆ—å‡º JSON æª”æ¡ˆ (æ™ºæ…§ç¯©é¸ç‰ˆ)ã€‚
    é‚è¼¯ï¼šé‡å°æ¯å€‹ Chunk IDï¼Œåªå›å‚³ã€Œæœ€é«˜å„ªå…ˆç´šã€çš„å–®ä¸€æª”æ¡ˆã€‚
    """
    json_files = []
    
    if case:
        search_path = os.path.join(DATA_DIR, case, "chunk_*.json")
    else:
        # å¦‚æœæ²’é¸ Caseï¼Œé€šå¸¸ä¸å›å‚³ï¼Œæˆ–å›å‚³å…¨éƒ¨ (è¦–éœ€æ±‚)
        return {"files": []}
    
    # 1. æª”æ¡ˆåˆ†çµ„ï¼šä»¥ Chunk ID ç‚º Key
    # çµæ§‹: { 1: {'flagged': path, 'aligned': path}, 2: {...} }
    chunk_groups = {}
    
    for f in glob.glob(search_path):
        filename = os.path.basename(f)
        
        # çµ•å°æ’é™¤çš„åå–®
        if "whisper" in filename or "diar" in filename:
            continue
            
        # è§£æ Chunk ID
        # æª”åç¯„ä¾‹: chunk_3_1100278_1606067_flagged_for_human.json
        try:
            parts = filename.split('_')
            # parts[0]="chunk", parts[1]="3" (index)
            chunk_idx = int(parts[1])
        except:
            continue # æª”åæ ¼å¼ä¸å°å°±è·³é
            
        if chunk_idx not in chunk_groups:
            chunk_groups[chunk_idx] = {}
            
        # ä¾æ“šå¾Œç¶´åˆ†é¡
        if "flagged_for_human" in filename:
            chunk_groups[chunk_idx]["flagged"] = f
        elif "edited" in filename:
            chunk_groups[chunk_idx]["edited"] = f
        elif "verified_dataset" in filename:
            chunk_groups[chunk_idx]["verified"] = f
        elif "aligned" in filename:
            chunk_groups[chunk_idx]["aligned"] = f
            
    # 2. æŒ‘é¸æ¯å€‹ Chunk çš„æœ€ä½³æª”æ¡ˆ (Winner Takes All)
    # æˆ‘å€‘å°‡ keys æ’åº (1, 2, 3, 4...) ç¢ºä¿åˆ—è¡¨é †åº
    sorted_indices = sorted(chunk_groups.keys())
    
    for idx in sorted_indices:
        variants = chunk_groups[idx]
        best_file = None
        
        # å„ªå…ˆé †åºåˆ¤å®š
        if "flagged" in variants:
            best_file = variants["flagged"]
        elif "edited" in variants:
            best_file = variants["edited"]
        elif "verified" in variants:
            best_file = variants["verified"]
        elif "aligned" in variants:
            best_file = variants["aligned"]
            
        if best_file:
            # è½‰ç›¸å°è·¯å¾‘å›å‚³
            rel_path = os.path.relpath(best_file, DATA_DIR)
            json_files.append(rel_path.replace("\\", "/"))
            
    return {"files": json_files}

@app.get("/api/temp/chunks")
def list_chunks(case: Optional[str] = None):
    """
    åˆ—å‡º JSON æª”æ¡ˆã€‚
    é‚è¼¯ï¼šé‡å°æ¯å€‹ Chunk ID (ä¾‹å¦‚ chunk_1)ï¼Œåªå›å‚³ã€Œæœ€é«˜å„ªå…ˆç´šã€çš„æª”æ¡ˆã€‚
    å„ªå…ˆç´š: flagged > edited > aligned (whisper/diar éš±è—)
    """
    json_files = []
    
    if case:
        search_path = os.path.join(DATA_DIR, case, "chunk_*.json")
    else:
        search_path = os.path.join(DATA_DIR, "*", "chunk_*.json")
    
    # 1. æ”¶é›†æ‰€æœ‰ chunk æª”æ¡ˆï¼Œä¸¦åˆ†çµ„
    # çµæ§‹: { "chunk_1": { "flagged": path, "aligned": path ... } }
    chunk_groups = {}
    
    for f in glob.glob(search_path):
        filename = os.path.basename(f)
        
        # æ’é™¤éç›®æ¨™æª”æ¡ˆ
        if "whisper" in filename or "diar" in filename:
            continue
            
        # è§£æ Chunk ID (å‡è¨­æª”å: chunk_1_0_531989_...)
        parts = filename.split('_')
        if len(parts) < 2: continue
        
        # çµ„åˆå‡ºå”¯ä¸€çš„ Key: CaseName/chunk_1
        case_name = os.path.basename(os.path.dirname(f))
        chunk_id = f"{parts[0]}_{parts[1]}" # chunk_1
        unique_key = f"{case_name}/{chunk_id}"
        
        if unique_key not in chunk_groups:
            chunk_groups[unique_key] = {}
            
        # åˆ†é¡
        if "flagged_for_human" in filename:
            chunk_groups[unique_key]["flagged"] = f
        elif "edited" in filename:
            chunk_groups[unique_key]["edited"] = f
        elif "aligned" in filename:
            chunk_groups[unique_key]["aligned"] = f
            
    # 2. æŒ‘é¸æœ€ä½³æª”æ¡ˆ
    for key, variants in chunk_groups.items():
        best_file = None
        # å„ªå…ˆé †åº: Flagged > Edited > Aligned
        if "flagged" in variants:
            best_file = variants["flagged"]
        elif "edited" in variants:
            best_file = variants["edited"]
        elif "aligned" in variants:
            best_file = variants["aligned"]
            
        if best_file:
            rel_path = os.path.relpath(best_file, DATA_DIR)
            json_files.append(rel_path.replace("\\", "/"))
            
    # 3. æ’åº (ç¢ºä¿ chunk_1, chunk_2 é †åºæ­£ç¢º)
    # æˆ‘å€‘éœ€è¦è‡ªè¨‚æ’åºéµï¼Œå› ç‚ºå­—ä¸²æ’åº "chunk_10" æœƒæ’åœ¨ "chunk_2" å‰é¢
    def sort_key(path):
        try:
            # path: Case/chunk_1_...
            filename = os.path.basename(path)
            parts = filename.split('_')
            return int(parts[1]) # å– chunk çš„ç·¨è™Ÿä¾†æ’åº
        except:
            return path

    json_files.sort(key=sort_key)
    return {"files": json_files}

@app.get("/api/temp/chunk/{filename:path}")
def get_chunk(filename: str):
    """
    è®€å–å°ˆæ¡ˆè³‡æ–™ (Version Control Logic)
    ä¿®æ­£ï¼šå„ªå…ˆé–å®šä¸»å½±ç‰‡ (MP4)ï¼Œä¿æŒå‰ç«¯æ’­æ”¾å™¨ä¸è·³å‹•ã€‚
    """
    try:
        base_path = get_real_path(filename)
        
        # 1. æ±ºå®šè¦è®€å“ªå€‹æª”æ¡ˆ (Version Control)
        flagged_path = base_path.replace(".json", "_flagged_for_human.json")
        edited_path = base_path.replace(".json", "_edited.json")
        
        target_path = base_path # é è¨­è®€åŸå§‹æª”
        
        if os.path.exists(flagged_path):
            target_path = flagged_path
            print(f"ğŸ“– Loading flagged: {os.path.basename(flagged_path)}")
        elif os.path.exists(edited_path):
            target_path = edited_path
            print(f"ğŸ“– Loading edited: {os.path.basename(edited_path)}")
        else:
            print(f"ğŸ“– Loading original: {os.path.basename(base_path)}")
        
        if not os.path.exists(target_path):
            raise HTTPException(status_code=404, detail="File not found")
        
        with open(target_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # ========================================================
        # 2. åª’é«”é…å°é‚è¼¯ (Media Discovery) - é—œéµä¿®æ­£è™•
        # ========================================================
        # ç›®æ¨™ï¼šä¸ç®¡é¸å“ªå€‹ chunkï¼Œéƒ½å„ªå…ˆå›å‚³è©²è³‡æ–™å¤¾çš„ä¸»å½±ç‰‡ (.mp4)
        # é€™æ¨£å‰ç«¯æ’­æ”¾å™¨æ‰ä¸æœƒå› ç‚ºåˆ‡æ› chunk è€Œé‡æ•´
        
        folder_path = os.path.dirname(filename)      # ç›¸å°è·¯å¾‘ (CaseName)
        real_folder = os.path.dirname(target_path)   # çµ•å°è·¯å¾‘
        
        target_media = None
        
        # ç­–ç•¥ A: å…ˆæ‰¾è©²è³‡æ–™å¤¾å…§çš„ MP4 (ä¸»å½±ç‰‡)
        if os.path.exists(real_folder):
            # å–å¾—è©²è³‡æ–™å¤¾å…§æ‰€æœ‰æª”æ¡ˆ
            files = os.listdir(real_folder)
            # å„ªå…ˆæ‰¾ .mp4 æˆ– .MP4
            mp4_files = [f for f in files if f.lower().endswith('.mp4')]
            
            if mp4_files:
                # ç°¡å–®é‚è¼¯ï¼šé€šå¸¸æœ€å¤§çš„é‚£å€‹å°±æ˜¯ä¸»å½±ç‰‡ï¼Œæˆ–è€…ç›´æ¥å–ç¬¬ä¸€å€‹
                # é€™è£¡æˆ‘å€‘å–æª”æ¡ˆåç¨±æœ€çŸ­çš„ï¼Œé€šå¸¸ä¸»å½±ç‰‡æª”åæ¯”è¼ƒä¹¾æ·¨ï¼Œæˆ–è€…å–ç¬¬ä¸€å€‹
                mp4_files.sort(key=len) 
                target_media = mp4_files[0]
        
        # ç­–ç•¥ B: å¦‚æœçœŸçš„æ²’æœ‰ MP4ï¼Œæ‰é€€è€Œæ±‚å…¶æ¬¡å»æ‰¾å°æ‡‰çš„ chunk éŸ³æª” (.wav)
        if not target_media:
            json_fname = os.path.basename(target_path)
            core_name = json_fname.replace("_flagged_for_human.json", "")\
                                  .replace("_edited.json", "")\
                                  .replace(".json", "")
            
            # ç§»é™¤å¾Œç¶´ä»¥é‚„åŸ chunk åç¨±
            for suffix in ["_whisper", "_aligned", "_diar"]:
                if core_name.endswith(suffix):
                    core_name = core_name.replace(suffix, "")

            # æ‰¾åŒåçš„ wav
            for ext in [".wav", ".mp3", ".m4a"]:
                candidate = f"{core_name}{ext}"
                if os.path.exists(os.path.join(real_folder, candidate)):
                    target_media = candidate
                    break
        
        # 3. è™•ç†å›å‚³è³‡æ–™
        processed_data = data if isinstance(data, dict) else {
            "segments": data, 
            "speaker_mapping": {}, 
            "file_type": "original"
        }
        
        # åªæœ‰åœ¨æ‰¾åˆ°åª’é«”æª”æ™‚æ‰æ›´æ–° media_file
        if target_media:
            # çµ„åˆç›¸å°è·¯å¾‘: CaseName/Video.mp4
            media_rel_path = f"{folder_path}/{target_media}"
            processed_data['media_file'] = media_rel_path.replace("\\", "/")
            
        # æ¨™è¨˜æª”æ¡ˆé¡å‹
        if "_flagged_for_human" in target_path:
            processed_data['file_type'] = 'flagged'
        elif "_edited" in target_path:
            processed_data['file_type'] = 'edited'
        else:
            processed_data['file_type'] = 'original'
            
        return processed_data

    except Exception as e:
        print(f"âŒ Error loading chunk: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/temp/save")
def save_chunk(payload: SavePayload):
    """
    å­˜æª” API (å¼·åˆ¶å­˜ç‚º _edited.json)
    """
    try:
        original_path = get_real_path(payload.filename)
        
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ _flagged æˆ– _edited å¾Œç¶´ï¼Œç¢ºä¿æª”åä¹¾æ·¨
        clean_path = original_path.replace("_flagged_for_human.json", ".json")\
                                  .replace("_edited.json", ".json")
        
        # ç”¢ç”Ÿå„²å­˜è·¯å¾‘
        save_path = clean_path.replace(".json", "_edited.json")
        
        data_to_save = {
            "last_modified": datetime.now().isoformat(),
            "speaker_mapping": payload.speaker_mapping,
            "segments": [s.dict() for s in payload.segments],
        }
        
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ’¾ Saved: {os.path.basename(save_path)}")
        return {"status": "success", "saved_to": save_path}
    
    except Exception as e:
        print(f"âŒ Save error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/upload")
async def upload_video(file: UploadFile = File(...), case_name: str = Form(...)):
    """
    ä¸Šå‚³æ–°å½±ç‰‡ä¸¦å»ºç«‹æ¡ˆä¾‹è³‡æ–™å¤¾
    """
    try:
        timestamp = datetime.now().strftime("%Y%m%d-%H%M")
        base_name = os.path.splitext(file.filename)[0]
        safe_base_name = base_name.replace(" ", "-")
        
        if not case_name.strip():
            case_name = f"{timestamp}-{safe_base_name}"
        
        # å„²å­˜åˆ° data/CaseName/
        save_dir = os.path.join(DATA_DIR, case_name)
        os.makedirs(save_dir, exist_ok=True)
        
        file_path = os.path.join(save_dir, file.filename)
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        print(f"âœ… Uploaded to: {save_dir}")
        return {"message": "Success", "path": file_path}
    
    except Exception as e:
        print(f"âŒ Upload error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # ç¢ºä¿ reload=True åœ¨é–‹ç™¼æ™‚å¾ˆå¥½ç”¨ï¼Œæœƒè‡ªå‹•åµæ¸¬ç¨‹å¼ç¢¼è®Šæ›´é‡å•Ÿ
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)