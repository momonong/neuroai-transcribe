import os
import json
import glob
import shutil
from datetime import datetime
from typing import List, Dict, Optional, Any
from pathlib import Path

from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

app = FastAPI()

# ==========================================
# 1. è¨­å®š & åˆå§‹åŒ– (è·¯å¾‘ä¿®æ­£æ ¸å¿ƒ)
# ==========================================

# å–å¾—ç•¶å‰æª”æ¡ˆ (backend/main.py) çš„çµ•å°è·¯å¾‘
CURRENT_FILE = os.path.abspath(__file__)
# å–å¾— backend è³‡æ–™å¤¾è·¯å¾‘
BACKEND_DIR = os.path.dirname(CURRENT_FILE)
# å–å¾—å°ˆæ¡ˆæ ¹ç›®éŒ„ (backend çš„ä¸Šä¸€å±¤)
PROJECT_ROOT = os.path.dirname(BACKEND_DIR)

# è¨­å®š DATA_DIR ç‚º å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ data
DATA_DIR = os.path.join(PROJECT_ROOT, "data")

# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)

print(f"ğŸš€ Server started.")
print(f"ğŸ“‚ Project Root: {PROJECT_ROOT}")
print(f"ğŸ“‚ Data Directory: {DATA_DIR}")

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ›è¼‰éœæ…‹æª”æ¡ˆ (å‰ç«¯æ’­æ”¾å½±ç‰‡ç”¨)
app.mount("/static", StaticFiles(directory=DATA_DIR), name="static")


# ==========================================
# 2. è³‡æ–™çµæ§‹ (Pydantic Models)
# ==========================================

class TranscriptSegment(BaseModel):
    sentence_id: float
    start: float
    end: float
    speaker: str
    text: str
    verification_score: float = 1.0
    status: str = "reviewed"
    needs_review: bool = False
    review_reason: Optional[str] = None

class SavePayload(BaseModel):
    filename: str  # ç›¸å°è·¯å¾‘ (CaseName/chunk_x.json)
    speaker_mapping: Dict[str, str]
    segments: List[TranscriptSegment]

# ==========================================
# 3. è¼”åŠ©å‡½å¼
# ==========================================

def get_real_path(relative_path: str):
    """å°‡å‰ç«¯å‚³ä¾†çš„ç›¸å°è·¯å¾‘è½‰æ›ç‚ºç³»çµ±çµ•å°è·¯å¾‘"""
    if ".." in relative_path:
        raise ValueError("Invalid path: '..' is not allowed")
    return os.path.join(DATA_DIR, relative_path)

# ==========================================
# 4. API å¯¦ä½œ
# ==========================================

@app.get("/api/videos")
def get_videos():
    """
    æƒææ‰€æœ‰å½±ç‰‡ï¼Œä¾›å‰ç«¯ä¸‹æ‹‰é¸å–®ä½¿ç”¨
    ä¿®æ­£ï¼šæƒæ data/CaseName/Video.mp4
    """
    video_files = []
    # æ”¯æ´å¸¸è¦‹éŸ³è¦–è¨Šæ ¼å¼
    extensions = [".mp4", ".MP4"]
    
    if not os.path.exists(DATA_DIR):
        return video_files
    
    # 1. æƒæ data è³‡æ–™å¤¾åº•ä¸‹çš„æ¯ä¸€å±¤ (Caseè³‡æ–™å¤¾)
    # ä½¿ç”¨ os.scandir æ•ˆèƒ½è¼ƒå¥½
    with os.scandir(DATA_DIR) as it:
        for entry in it:
            if entry.is_dir() and entry.name not in ["temp_chunks", "db", "text", "__pycache__"]:
                case_name = entry.name
                case_path = entry.path
                
                # 2. åœ¨è©² Case è³‡æ–™å¤¾å…§æ‰¾å½±ç‰‡
                for f in os.listdir(case_path):
                    if any(f.endswith(ext) for ext in extensions):
                        # æ’é™¤æ‰ chunk_ é–‹é ­çš„éŸ³æª”ï¼Œæˆ‘å€‘åªåˆ—å‡ºä¸»å½±ç‰‡
                        if f.startswith("chunk_"):
                            continue
                            
                        # çµ„åˆç›¸å°è·¯å¾‘
                        rel_path = f"{case_name}/{f}"
                        display_name = f"{case_name}"
                        
                        video_files.append({
                            "path": rel_path,
                            "name": display_name
                        })

    # ä¾åç¨±æ’åº
    video_files.sort(key=lambda x: x['name'], reverse=True)
    return video_files

@app.get("/api/cases")
def get_cases():
    """
    åˆ—å‡º data/ åº•ä¸‹çš„å°ˆæ¡ˆè³‡æ–™å¤¾
    """
    cases = []
    if not os.path.exists(DATA_DIR):
        return cases
    
    # å¿½ç•¥çš„ç³»çµ±è³‡æ–™å¤¾
    IGNORE_DIRS = {"temp_chunks", "db", "text", "__pycache__", "output", "test-complete-pipeline"}

    with os.scandir(DATA_DIR) as it:
        for entry in it:
            if entry.is_dir() and entry.name not in IGNORE_DIRS:
                # åªè¦ä¸æ˜¯ç³»çµ±è³‡æ–™å¤¾ï¼Œæˆ‘å€‘å°±ç•¶ä½œæ˜¯æ¡ˆä¾‹è³‡æ–™å¤¾å›å‚³
                # ä¸åšéåº¦æª¢æŸ¥ï¼Œä»¥å…å› ç‚ºæª”æ¡ˆæ ¼å¼å•é¡Œå°è‡´è³‡æ–™å¤¾æ¶ˆå¤±
                cases.append(entry.name)
    
    cases.sort(reverse=True)
    return cases

@app.get("/api/temp/chunks")
def list_chunks(case: Optional[str] = None):
    """
    åˆ—å‡º JSON æª”æ¡ˆ (æ™ºæ…§ç¯©é¸ç‰ˆ)ã€‚
    é‚è¼¯ï¼šé‡å°æ¯å€‹ Chunk IDï¼Œåªå›å‚³ã€Œæœ€é«˜å„ªå…ˆç´šã€çš„å–®ä¸€æª”æ¡ˆã€‚
    """
    json_files = []
    
    if case:
        search_path = os.path.join(DATA_DIR, case, "chunk_*.json")
    else:
        # å¦‚æœæ²’é¸ Caseï¼Œé€šå¸¸ä¸å›å‚³ï¼Œæˆ–å›å‚³å…¨éƒ¨ (è¦–éœ€æ±‚)
        return {"files": []}
    
    # 1. æª”æ¡ˆåˆ†çµ„ï¼šä»¥ Chunk ID ç‚º Key
    # çµæ§‹: { 1: {'flagged': path, 'aligned': path}, 2: {...} }
    chunk_groups = {}
    
    for f in glob.glob(search_path):
        filename = os.path.basename(f)
        
        # çµ•å°æ’é™¤çš„åå–®
        if "whisper" in filename or "diar" in filename:
            continue
            
        # è§£æ Chunk ID
        # æª”åç¯„ä¾‹: chunk_3_1100278_1606067_flagged_for_human.json
        try:
            parts = filename.split('_')
            # parts[0]="chunk", parts[1]="3" (index)
            chunk_idx = int(parts[1])
        except:
            continue # æª”åæ ¼å¼ä¸å°å°±è·³é
            
        if chunk_idx not in chunk_groups:
            chunk_groups[chunk_idx] = {}
            
        # ä¾æ“šå¾Œç¶´åˆ†é¡
        if "flagged_for_human" in filename:
            chunk_groups[chunk_idx]["flagged"] = f
        elif "edited" in filename:
            chunk_groups[chunk_idx]["edited"] = f
        elif "verified_dataset" in filename:
            chunk_groups[chunk_idx]["verified"] = f
        elif "aligned" in filename:
            chunk_groups[chunk_idx]["aligned"] = f
            
    # 2. æŒ‘é¸æ¯å€‹ Chunk çš„æœ€ä½³æª”æ¡ˆ (Winner Takes All)
    # æˆ‘å€‘å°‡ keys æ’åº (1, 2, 3, 4...) ç¢ºä¿åˆ—è¡¨é †åº
    sorted_indices = sorted(chunk_groups.keys())
    
    for idx in sorted_indices:
        variants = chunk_groups[idx]
        best_file = None
        
        # å„ªå…ˆé †åºåˆ¤å®š
        if "flagged" in variants:
            best_file = variants["flagged"]
        elif "edited" in variants:
            best_file = variants["edited"]
        elif "verified" in variants:
            best_file = variants["verified"]
        elif "aligned" in variants:
            best_file = variants["aligned"]
            
        if best_file:
            # è½‰ç›¸å°è·¯å¾‘å›å‚³
            rel_path = os.path.relpath(best_file, DATA_DIR)
            json_files.append(rel_path.replace("\\", "/"))
            
    return {"files": json_files}

@app.get("/api/temp/chunks")
def list_chunks(case: Optional[str] = None):
    """
    åˆ—å‡º JSON æª”æ¡ˆ (æ™ºæ…§ç¯©é¸ç‰ˆ)ã€‚
    é‚è¼¯ï¼šé‡å°æ¯å€‹ Chunk IDï¼Œåªå›å‚³ã€Œæœ€é«˜å„ªå…ˆç´šã€çš„å–®ä¸€æª”æ¡ˆã€‚
    ä¿®æ­£å¾Œå„ªå…ˆç´š: edited > flagged > verified > aligned
    """
    json_files = []
    
    if case:
        search_path = os.path.join(DATA_DIR, case, "chunk_*.json")
    else:
        search_path = os.path.join(DATA_DIR, "*", "chunk_*.json")
    
    # 1. æ”¶é›†æ‰€æœ‰ chunk æª”æ¡ˆï¼Œä¸¦åˆ†çµ„
    chunk_groups = {}
    
    for f in glob.glob(search_path):
        filename = os.path.basename(f)
        
        # æ’é™¤éç›®æ¨™æª”æ¡ˆ
        if "whisper" in filename or "diar" in filename:
            continue
            
        # è§£æ Chunk ID
        parts = filename.split('_')
        if len(parts) < 2: continue
        
        case_name = os.path.basename(os.path.dirname(f))
        chunk_id = f"{parts[0]}_{parts[1]}" # chunk_1
        unique_key = f"{case_name}/{chunk_id}"
        
        if unique_key not in chunk_groups:
            chunk_groups[unique_key] = {}
            
        # åˆ†é¡
        if "flagged_for_human" in filename:
            chunk_groups[unique_key]["flagged"] = f
        elif "edited" in filename:
            chunk_groups[unique_key]["edited"] = f
        elif "verified_dataset" in filename:
            chunk_groups[unique_key]["verified"] = f
        elif "aligned" in filename:
            chunk_groups[unique_key]["aligned"] = f
            
    # 2. æŒ‘é¸æœ€ä½³æª”æ¡ˆ (Winner Takes All)
    for key, variants in chunk_groups.items():
        best_file = None
        
        # ğŸ”¥ ä¿®æ­£é‡é»ï¼šå„ªå…ˆé †åºèª¿æ•´ ğŸ”¥
        # åªè¦æœ‰ "å·²ç·¨è¼¯ (edited)" ç‰ˆæœ¬ï¼Œä»£è¡¨äººå·¥å·²ç¶“è™•ç†éï¼Œçµ•å°å„ªå…ˆé¡¯ç¤ºï¼
        if "edited" in variants:
            best_file = variants["edited"]      # ğŸ¥‡ ç¬¬ä¸€é †ä½: å·²ç·¨è¼¯
        elif "flagged" in variants:
            best_file = variants["flagged"]     # ğŸ¥ˆ ç¬¬äºŒé †ä½: éœ€å¯©æ ¸
        elif "verified" in variants:
            best_file = variants["verified"]    # ğŸ¥‰ ç¬¬ä¸‰é †ä½: å·²é©—è­‰è³‡æ–™é›†
        elif "aligned" in variants:
            best_file = variants["aligned"]     # ğŸ… ç¬¬å››é †ä½: åŸå§‹æª”
            
        if best_file:
            rel_path = os.path.relpath(best_file, DATA_DIR)
            json_files.append(rel_path.replace("\\", "/"))
            
    # 3. æ’åº (ç¢ºä¿ chunk_1, chunk_2 é †åºæ­£ç¢º)
    def sort_key(path):
        try:
            filename = os.path.basename(path)
            parts = filename.split('_')
            return int(parts[1]) 
        except:
            return path

    json_files.sort(key=sort_key)
    return {"files": json_files}

@app.get("/api/temp/chunk/{filename:path}")
def get_chunk(filename: str):
    """
    è®€å–å°ˆæ¡ˆè³‡æ–™ (æ™ºæ…§å„ªå…ˆç´šç‰ˆ)ã€‚
    é‚è¼¯ï¼šä¸ç®¡å‚³å…¥ä»€éº¼æª”åï¼Œä¸€å¾‹å„ªå…ˆå°‹æ‰¾ä¸¦å›å‚³ 'å·²ç·¨è¼¯ (_edited)' ç‰ˆæœ¬ã€‚
    å„ªå…ˆç´š: Edited > Flagged > Verified > Aligned
    """
    try:
        # 1. å–å¾—çµ•å°è·¯å¾‘
        request_path = get_real_path(filename)
        directory = os.path.dirname(request_path)
        request_fname = os.path.basename(request_path)
        
        # 2. é‚„åŸã€Œæ ¸å¿ƒæª”åã€ (ç§»é™¤æ‰€æœ‰å¯èƒ½çš„å¾Œç¶´)
        # ä¾‹å¦‚: chunk_1_0_531989_flagged_for_human.json -> chunk_1_0_531989
        core_name = request_fname.replace("_flagged_for_human.json", "")\
                                 .replace("_edited.json", "")\
                                 .replace("_verified_dataset.json", "")\
                                 .replace("_aligned.json", "")\
                                 .replace(".json", "")
        
        # ç§»é™¤å¯èƒ½æ®˜ç•™çš„å¾Œç¶´ (é‡å° whisper/diar é€™ç¨®éæ¨™æº–çµå°¾)
        for suffix in ["_whisper", "_aligned", "_diar"]:
            if core_name.endswith(suffix):
                core_name = core_name.replace(suffix, "")

        # 3. å®šç¾©å„ç‰ˆæœ¬çš„å€™é¸è·¯å¾‘
        candidate_edited = os.path.join(directory, f"{core_name}_edited.json")
        candidate_flagged = os.path.join(directory, f"{core_name}_flagged_for_human.json")
        candidate_verified = os.path.join(directory, f"{core_name}_verified_dataset.json")
        candidate_aligned = os.path.join(directory, f"{core_name}_aligned.json")
        
        # 4. ä¾ç…§å„ªå…ˆæ¬Šæ±ºå®šæœ€çµ‚è¦è®€å–å“ªå€‹æª”æ¡ˆ (Winner Takes All)
        target_path = None
        
        if os.path.exists(candidate_edited):
            target_path = candidate_edited
            print(f"ğŸ“– Priority Load: Edited ({os.path.basename(target_path)})")
        elif os.path.exists(candidate_flagged):
            target_path = candidate_flagged
            print(f"ğŸ“– Priority Load: Flagged ({os.path.basename(target_path)})")
        elif os.path.exists(candidate_verified):
            target_path = candidate_verified
        elif os.path.exists(candidate_aligned):
            target_path = candidate_aligned
        else:
            # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œå°±å˜—è©¦è®€å–åŸæœ¬è«‹æ±‚çš„æª”æ¡ˆ (Fallback)
            target_path = request_path
            print(f"ğŸ“– Fallback Load: {os.path.basename(target_path)}")

        if not os.path.exists(target_path):
            raise HTTPException(status_code=404, detail="File not found")
        
        # 5. è®€å–æª”æ¡ˆå…§å®¹
        with open(target_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        # ========================================================
        # 6. åª’é«”é…å°é‚è¼¯ (Media Discovery) - ç¶­æŒä¸è®Š (æ‰¾ MP4 å„ªå…ˆ)
        # ========================================================
        folder_path = os.path.dirname(filename)      # ç›¸å°è·¯å¾‘
        real_folder = os.path.dirname(target_path)   # çµ•å°è·¯å¾‘
        target_media = None
        
        # ç­–ç•¥ A: æ‰¾ä¸»å½±ç‰‡ (.mp4)
        if os.path.exists(real_folder):
            files = os.listdir(real_folder)
            mp4_files = [f for f in files if f.lower().endswith('.mp4')]
            if mp4_files:
                mp4_files.sort(key=len) 
                target_media = mp4_files[0]
        
        # ç­–ç•¥ B: æ‰¾å°æ‡‰éŸ³æª” (.wav)
        if not target_media:
            # å˜—è©¦æ‰¾ chunk wav
            for ext in [".wav", ".mp3", ".m4a"]:
                candidate = f"{core_name}{ext}"
                if os.path.exists(os.path.join(real_folder, candidate)):
                    target_media = candidate
                    break
        
        # 7. çµ„è£å›å‚³è³‡æ–™
        processed_data = data if isinstance(data, dict) else {
            "segments": data, 
            "speaker_mapping": {}, 
            "file_type": "original"
        }
        
        if target_media:
            media_rel_path = f"{folder_path}/{target_media}"
            processed_data['media_file'] = media_rel_path.replace("\\", "/")
            
        # æ¨™è¨˜æª”æ¡ˆé¡å‹ (çµ¦å‰ç«¯é¡¯ç¤º Chip ç”¨)
        if "_flagged_for_human" in target_path:
            processed_data['file_type'] = 'flagged'
        elif "_edited" in target_path:
            processed_data['file_type'] = 'edited'
        else:
            processed_data['file_type'] = 'original'
            
        return processed_data

    except Exception as e:
        print(f"âŒ Error loading chunk: {e}")
        raise HTTPException(status_code=500, detail=str(e))
        
@app.post("/api/temp/save")
def save_chunk(payload: SavePayload):
    """
    å­˜æª” APIã€‚
    é‚è¼¯ï¼šä¸ç®¡ä¾†æºæ˜¯ aligned, flagged é‚„æ˜¯ editedï¼Œ
    å­˜æª”æ™‚ä¸€å¾‹è½‰å­˜ç‚º '_edited.json'ï¼Œç¢ºä¿æ•¸æ“šä¸ä¸Ÿå¤±ä¸”æœ‰è·¡å¯å¾ªã€‚
    """
    try:
        # 1. è§£æåŸå§‹è·¯å¾‘
        full_path = get_real_path(payload.filename)
        directory = os.path.dirname(full_path)
        filename = os.path.basename(full_path)
        
        # 2. å»ºæ§‹ç›®æ¨™æª”å (å¼·åˆ¶çµå°¾ç‚º _edited.json)
        # å…ˆç§»é™¤æ‰€æœ‰å¯èƒ½çš„å¾Œç¶´ï¼Œé‚„åŸåˆ°æ ¸å¿ƒ ID
        core_name = filename.replace("_flagged_for_human.json", "")\
                            .replace("_edited.json", "")\
                            .replace("_aligned.json", "")\
                            .replace("_verified_dataset.json", "")\
                            .replace(".json", "")
        
        # åŠ ä¸Š _edited å¾Œç¶´
        new_filename = f"{core_name}_edited.json"
        save_path = os.path.join(directory, new_filename)
        
        # 3. æº–å‚™è³‡æ–™
        data_to_save = {
            "last_modified": datetime.now().isoformat(),
            "speaker_mapping": payload.speaker_mapping,
            "segments": [s.dict() for s in payload.segments],
        }
        
        # 4. å¯«å…¥æª”æ¡ˆ
        with open(save_path, "w", encoding="utf-8") as f:
            json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            
        print(f"ğŸ’¾ Saved to: {new_filename}")
        
        # 5. å›å‚³æ–°çš„ç›¸å°è·¯å¾‘ (é‡è¦ï¼è®“å‰ç«¯å¯ä»¥æ›´æ–°ç‹€æ…‹)
        # è¨ˆç®—ç›¸å°è·¯å¾‘: CaseName/chunk_x_edited.json
        relative_path = os.path.relpath(save_path, DATA_DIR).replace("\\", "/")
        
        return {
            "status": "success", 
            "saved_to": relative_path,
            "filename": new_filename
        }
    
    except Exception as e:
        print(f"âŒ Save error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/upload")
async def upload_video(file: UploadFile = File(...), case_name: str = Form(...)):
    """
    ä¸Šå‚³æ–°å½±ç‰‡ä¸¦å»ºç«‹æ¡ˆä¾‹è³‡æ–™å¤¾
    """
    try:
        timestamp = datetime.now().strftime("%Y%m%d-%H%M")
        base_name = os.path.splitext(file.filename)[0]
        safe_base_name = base_name.replace(" ", "-")
        
        if not case_name.strip():
            case_name = f"{timestamp}-{safe_base_name}"
        
        # å„²å­˜åˆ° data/CaseName/
        save_dir = os.path.join(DATA_DIR, case_name)
        os.makedirs(save_dir, exist_ok=True)
        
        file_path = os.path.join(save_dir, file.filename)
        with open(file_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
            
        print(f"âœ… Uploaded to: {save_dir}")
        return {"message": "Success", "path": file_path}
    
    except Exception as e:
        print(f"âŒ Upload error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # ç¢ºä¿ reload=True åœ¨é–‹ç™¼æ™‚å¾ˆå¥½ç”¨ï¼Œæœƒè‡ªå‹•åµæ¸¬ç¨‹å¼ç¢¼è®Šæ›´é‡å•Ÿ
    uvicorn.run("main:app", host="0.0.0.0", port=8001, reload=True)