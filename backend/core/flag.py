import json
import time
from typing import List, Optional, Literal
from enum import Enum
from pydantic import BaseModel, Field
import instructor
from openai import OpenAI, APITimeoutError, APIConnectionError

# å¼•å…¥é…ç½®ï¼Œç¢ºä¿ API Key å’Œ URL èˆ‡ pipeline ä¸€è‡´
from .config import config

# --- 1. å®šç¾©è³‡æ–™çµæ§‹ ---
class IssueCategory(str, Enum):
    LIKELY_ASR_ERROR = "Likely_ASR_Error"     # è½èµ·ä¾†åƒåŒéŸ³å­—éŒ¯èª¤
    CONTEXT_MISMATCH = "Context_Mismatch"     # ä¸Šä¸‹æ–‡ä¸é€šé †
    UNINTELLIGIBLE = "Unintelligible"         # èªžæ„ä¸æ˜Ž
    # ASD ç‰¹å¾µä¿ç•™ (å¯é¸)
    # ECHOLALIA = "Echolalia" 

class SentenceHealth(BaseModel):
    sentence_id: int
    is_suspicious: bool = Field(..., description="True if text seems wrong/weird.")
    issue_category: Optional[IssueCategory] = Field(None)
    reason: Optional[str] = Field(None)
    
    # ðŸ‘‡ðŸ‘‡ðŸ‘‡ æ ¸å¿ƒæ–°å¢žï¼šå»ºè­°ä¿®æ­£æ¬„ä½ ðŸ‘‡ðŸ‘‡ðŸ‘‡
    suggested_correction: Optional[str] = Field(
        None, 
        description="The corrected text IF it is an ASR error. If it is just weird speech behavior (echolalia), leave this null."
    )

class HealthReport(BaseModel):
    assessments: List[SentenceHealth]

# --- 2. åˆå§‹åŒ– Agent ---
client = OpenAI(
    base_url=config.llm_api_url, 
    api_key=config.openai_api_key, 
    timeout=120.0  # è¨­å®š 120 ç§’ï¼Œé¿å… Local LLM é‹ç®—éŽä¹…å°Žè‡´è¶…æ™‚
)
agent = instructor.patch(client, mode=instructor.Mode.JSON)

def analyze_batch_safe(batch_sentences: List[dict]) -> Optional[HealthReport]:
    """
    å‘¼å« LLM é€²è¡Œåˆ†æžï¼Œå¸¶æœ‰é‡è©¦æ©Ÿåˆ¶
    """
    # æº–å‚™ Prompt ä¸Šä¸‹æ–‡
    context = "\n".join([f"[ID {s.get('sentence_id', i)}] {s['text']}" for i, s in enumerate(batch_sentences)])
    
    # ðŸ‘‡ðŸ‘‡ðŸ‘‡ ASD å°ˆç”¨é˜²å‘† Prompt ðŸ‘‡ðŸ‘‡ðŸ‘‡
    system_prompt = """
    You are a Transcription QA Agent specializing in NeuroAI datasets. 
    Your job is to flag Automatic Speech Recognition (ASR) errors (e.g., homophones, typos).
    
    CRITICAL RULE:
    - This is an Autism Spectrum Disorder (ASD) dataset.
    - DO NOT flag or correct repetitive speech (echolalia), stuttering, or short phrases as errors. These are valid behavioral data.
    - ONLY flag obvious phonetic ASR mistakes (e.g., "The sky is glue" -> "The sky is blue").
    
    If you find an ASR error:
    1. Set is_suspicious = True
    2. Provide the 'suggested_correction' (what the speaker likely meant).
    
    If the sentence is just repetitive or characteristic of ASD:
    1. Set is_suspicious = False
    2. Leave suggested_correction as null.
    """

    # 3. é¡¯å¼é‡è©¦è¿´åœˆ
    max_retries = 3
    for attempt in range(max_retries):
        try:
            resp = agent.chat.completions.create(
                model="gemma-2-9b-it", # ç¢ºèªä½ çš„æ¨¡åž‹åç¨±
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context}
                ],
                response_model=HealthReport,
                temperature=0.1,
                max_retries=2 
            )
            return resp
            
        except (APITimeoutError, APIConnectionError) as e:
            print(f"      âš ï¸ Timeout (Attempt {attempt+1}/{max_retries}). Retrying...", end="\r", flush=True)
            time.sleep(2)
        except Exception as e:
            print(f"      âš ï¸ Flag Agent Error (Attempt {attempt+1}): {e}")
            time.sleep(1)
            
    return None

# --- 4. æ ¸å¿ƒå…¥å£ ---
def run_anomaly_detector(data: List[dict]) -> List[dict]:
    print(f"ðŸ›¡ï¸ Starting Anomaly/QA Detection (Total: {len(data)} sentences)...")
    
    # åˆå§‹åŒ–æ¬„ä½
    for idx, item in enumerate(data):
        if 'sentence_id' not in item:
            item['sentence_id'] = idx
        item['needs_review'] = False
        item['review_reason'] = None
        item['suggested_correction'] = None # åˆå§‹åŒ–å»ºè­°æ¬„ä½

    # è¨­å®š Batch Size ç‚º 5 (ç©©å®šæ€§å„ªå…ˆ)
    batch_size = 5 
    total_batches = (len(data) + batch_size - 1) // batch_size

    for i in range(0, len(data), batch_size):
        batch = data[i : i + batch_size]
        
        current_batch = (i // batch_size) + 1
        print(f"   Processing Batch {current_batch}/{total_batches}...", end="", flush=True)
        
        report = analyze_batch_safe(batch)
        
        if report:
            print(f" Done.", flush=True)
            # å»ºç«‹æŸ¥è¡¨å­—å…¸
            assessment_map = {a.sentence_id: a for a in report.assessments}
            
            for item in batch:
                sid = item['sentence_id']
                if sid in assessment_map:
                    assessment = assessment_map[sid]
                    
                    # åªæœ‰çœŸçš„æœ‰å•é¡Œæ™‚æ‰æ¨™è¨˜
                    if assessment.is_suspicious:
                        item['needs_review'] = True
                        item['review_reason'] = f"[{assessment.issue_category}] {assessment.reason}"
                        # å„²å­˜å»ºè­°ä¿®æ­£
                        item['suggested_correction'] = assessment.suggested_correction
                        
                        # (å¯é¸) Debug é¡¯ç¤º
                        # print(f"\n      ðŸš© Flagged: {item['text']} -> Suggest: {assessment.suggested_correction}")
        else:
            print(f" Failed. Skipping flags.", flush=True)
            for item in batch:
                item['review_reason'] = "Analysis_Failed"

    print("\nâœ… Anomaly Detector Finished.")
    return data