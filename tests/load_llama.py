import torch
from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig
import json
import re
import os
from dotenv import load_dotenv

# ==========================================
# 1. ç’°å¢ƒè¨­å®š
# ==========================================
load_dotenv()
MODEL_PATH = os.getenv("LLAMA_MODEL_PATH")

if not MODEL_PATH:
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°ç’°å¢ƒè®Šæ•¸ 'LLAMA_MODEL_PATH'")
    exit()

print(f"ğŸ”„ æ­£åœ¨è¼‰å…¥æ¨¡å‹: {MODEL_PATH}")
print("âš¡ å•Ÿç”¨ 4-bit é‡åŒ– (Complex Scenario Test)...")

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        quantization_config=bnb_config,
        device_map="auto"
    )
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    exit()

# ==========================================
# 2. å®šç¾©ã€Œè¤‡é›œã€è‡¨åºŠæ¸¬è©¦ Prompt
# ==========================================
print("\nğŸ¤– æ­£åœ¨åŸ·è¡Œ Agent è¤‡é›œæ¨ç† (Complex Scenario)...")

# ==========================================
# ä¿®æ­£ç‰ˆï¼šå¼·åˆ¶ç¹é«”ä¸­æ–‡è¼¸å‡ºçš„ Prompt
# ==========================================
complex_clinical_prompt = """
You are a precise Clinical Scribe Agent for an ASD screening session in Taiwan.
Your task is to process raw ASR transcripts into a structured, verbatim dataset.

Context: The clinician is holding a toy Lion (ç…å­) and making roaring sounds to engage the child.
Input Transcript:
[00:15] "çœ‹ é€™å€‹ æ˜¯ ä»€éº¼ å¤§å¤§çš„ å¼ æ˜¯ ç…å­" (Clinician, Clear)
[00:20] "Shi... shi... uh..." (Child, Stuttering, Unclear)
[00:22] "å° ç…å­ ä½ èªª ç…å­" (Clinician, Encouraging)
[00:25] "O... zi..." (Child, Very Unclear)

Instructions:
1. Identify Speakers: Assign 'Clinician' (é†«å¸«) or 'Child' (å…’ç«¥).
2. Contextual Restoration (Must be in Traditional Chinese ç¹é«”ä¸­æ–‡):
   - If the child stutters (e.g., "Shi... shi..."), PRESERVE the repetition in 'original'.
   - In 'restored', clarify the meaning in Chinese (e.g., "ç…... (ç…å­)... ç…...").
   - Use the clinician's cue ("It's a Lion") to fix "O... zi..." into "ç…å­".
3. Reasoning: Explain your logic briefly in Traditional Chinese.
4. Output strictly in JSON format.

JSON Schema:
{
  "dialogue": [
    { "timestamp": "string", "speaker": "Clinician" | "Child", "text": "string" },
    { 
      "timestamp": "string", 
      "speaker": "Clinician" | "Child", 
      "original": "string", 
      "restored": "string (Traditional Chinese)", 
      "reasoning": "string (Traditional Chinese)" 
    }
  ]
}
"""

messages = [
    {"role": "user", "content": complex_clinical_prompt},
]

input_ids = tokenizer.apply_chat_template(
    messages,
    add_generation_prompt=True,
    return_tensors="pt"
).to(model.device)

terminators = [
    tokenizer.eos_token_id,
    tokenizer.convert_tokens_to_ids("<|eot_id|>")
]

# ==========================================
# 3. åŸ·è¡Œæ¨è«–
# ==========================================
print("â³ Agent æ­£åœ¨è§£æè¤‡é›œå°è©±...")

outputs = model.generate(
    input_ids,
    max_new_tokens=1024, # å¢åŠ é•·åº¦ä»¥å®¹ç´å¤šè¼ªå°è©±
    eos_token_id=terminators,
    do_sample=True,
    temperature=0.1, 
    top_p=0.9,
)

response = tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)

# ==========================================
# 4. çµæœé©—è­‰
# ==========================================
print("-" * 50)
# print("ğŸ“„ åŸå§‹è¼¸å‡º:\n", response) # Debugç”¨ï¼Œå¤ªé•·å¯ä»¥è¨»è§£æ‰
# print("-" * 50)


print("\nğŸ” é©—è­‰çµæœ:")

try:
    json_match = re.search(r'\{.*\}', response, re.DOTALL)
    
    if json_match:
        clean_json = json_match.group(0)
        data = json.loads(clean_json)
        
        print("âœ… JSON è§£ææˆåŠŸï¼")
        
        # --- é€™è£¡åŠ å…¥é€™è¡Œï¼ŒæŠŠå®Œæ•´çš„ JSON å°å‡ºä¾†çµ¦ä½ çœ‹ï¼Œæœ€ä¿éšª ---
        print("\nğŸ“„ å®Œæ•´ JSON è³‡æ–™ (Debug):")
        print(json.dumps(data, indent=2, ensure_ascii=False))
        print("-" * 30)
        # ----------------------------------------------------

        # é¡¯ç¤ºæ¯ä¸€å¥çš„è§£æçµæœ (ä¿®æ­£åˆ¤æ–·é‚è¼¯)
        for i, turn in enumerate(data['dialogue']):
            speaker = turn.get('speaker', 'Unknown')
            print(f"\n[Turn {i+1}] Speaker: {speaker}")
            
            # åˆ¤æ–·æ˜¯å¦ç‚ºå…’ç«¥ (å…¼å®¹è‹±æ–‡ 'Child' å’Œä¸­æ–‡ 'å…’ç«¥')
            if 'Child' in speaker or 'å…’ç«¥' in speaker:
                print(f"  ğŸ”Š åŸå§‹éŒ„éŸ³: {turn.get('original')}")
                print(f"  âœ¨ ä¿®å¾©çµæœ: {turn.get('restored')}")
                print(f"  ğŸ§  æ¨ç†é‚è¼¯: {turn.get('reasoning')}")
            else:
                # é†«å¸«çš„éƒ¨åˆ†
                print(f"  ğŸ’¬ å…§å®¹: {turn.get('text')}")
                
        # ç°¡å–®çš„è‡ªå‹•é€šéæ¨™æº–
        child_turns = [t for t in data['dialogue'] if 'Child' in t['speaker'] or 'å…’ç«¥' in t['speaker']]
        if len(child_turns) >= 2:
            print("\nâœ¨ æ¸¬è©¦çµè«–: æˆåŠŸï¼Agent èƒ½å¤ è™•ç†å¤šè¼ªå°è©±ä¸¦ä¿®å¾©é‡è¤‡èˆ‡æ¨¡ç³ŠèªéŸ³ã€‚")
        
    else:
        print("âŒ æœªæ‰¾åˆ° JSON å€å¡Š")
        print("åŸå§‹å›æ‡‰:", response)

except Exception as e:
    print(f"âš ï¸ è§£æéŒ¯èª¤: {e}")