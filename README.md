# NeuroAI Clinical Transcription System

A comprehensive AI-powered clinical audio transcription and annotation system designed for ASD (Autism Spectrum Disorder) diagnostic interviews. The system combines advanced speech recognition, speaker diarization, and intelligent post-processing to create accurate, reviewable transcripts for clinical use.

## ğŸ—ï¸ Architecture Overview

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend      â”‚    â”‚   AI Pipeline   â”‚
â”‚   (React/TS)    â”‚â—„â”€â”€â–ºâ”‚   (FastAPI)     â”‚â—„â”€â”€â–ºâ”‚   (Whisper +    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚    Pyannote)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Interface â”‚    â”‚   REST API      â”‚    â”‚   GPU Models    â”‚
â”‚   - Video Playerâ”‚    â”‚   - File Mgmt   â”‚    â”‚   - Whisper     â”‚
â”‚   - Text Editor â”‚    â”‚   - Processing  â”‚    â”‚   - Pyannote    â”‚
â”‚   - Annotation  â”‚    â”‚   - Validation  â”‚    â”‚   - LLM (Gemma) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Hardware**: NVIDIA GPU (RTX 3060+ recommended)
- **Software**: Docker, Docker Compose, Python 3.9+, Node.js 18+
- **Models**: Hugging Face account with access to Pyannote models

### Environment Setup

1. **Clone and configure environment**:
```bash
git clone <repository-url>
cd neuroai-transcription
cp .env.example .env
```

2. **Configure `.env` file**:
```env
# Model Configuration
MODEL_CACHE_DIR=D:/hf_models  # Adjust to your model storage path
HF_TOKEN=your_huggingface_token_here

# Docker Configuration
HOST_LLM_PORT=8000
HOST_BACKEND_PORT=8001
```

3. **Start the system**:
```bash
# Start all services
docker-compose up -d

# Or start individual services
docker-compose up llm-server    # LLM server only
docker-compose up backend       # Backend API only
```

### Manual Setup (Development)

**Backend Setup**:
```bash
cd backend
pip install -r requirements.txt
python main.py  # Starts on port 8001
```

**Frontend Setup**:
```bash
cd frontend
npm install
npm run dev     # Starts on port 5173
```

## ğŸ“ Project Structure

### Backend Architecture (`/backend`)

```
backend/
â”œâ”€â”€ main.py                 # FastAPI application entry point
â”œâ”€â”€ app.py                  # Streamlit annotation interface
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ Dockerfile             # Container configuration
â”œâ”€â”€ core/                  # Core AI processing modules
â”‚   â”œâ”€â”€ ai_engine.py       # Main pipeline orchestrator
â”‚   â”œâ”€â”€ pipeline.py        # Whisper + Pyannote processing
â”‚   â”œâ”€â”€ split.py           # Audio segmentation
â”‚   â”œâ”€â”€ stitch.py          # Sentence reconstruction
â”‚   â””â”€â”€ flag.py            # Quality assurance & flagging
â”œâ”€â”€ scripts/               # Processing scripts
â”‚   â”œâ”€â”€ transcribe.py      # Standalone transcription
â”‚   â”œâ”€â”€ diarization.py     # Speaker identification
â”‚   â””â”€â”€ agent/             # AI agent modules
â””â”€â”€ tests/                 # Unit and integration tests
```

### Frontend Architecture (`/frontend`)

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx            # Main React application
â”‚   â”œâ”€â”€ main.tsx           # Application entry point
â”‚   â”œâ”€â”€ App.css            # Styling
â”‚   â””â”€â”€ assets/            # Static resources
â”œâ”€â”€ package.json           # Node.js dependencies
â”œâ”€â”€ vite.config.ts         # Vite build configuration
â”œâ”€â”€ tsconfig.json          # TypeScript configuration
â””â”€â”€ public/                # Public assets
```

## ğŸ”§ Core Features

### AI Processing Pipeline

1. **Audio Splitting** (`core/split.py`)
   - Intelligent audio segmentation
   - Configurable chunk sizes
   - Metadata preservation

2. **Speech Recognition** (`core/pipeline.py`)
   - Whisper large-v3 model
   - Chinese language optimization
   - Word-level timestamps

3. **Speaker Diarization** (`core/pipeline.py`)
   - Pyannote 3.1 speaker identification
   - Multi-speaker conversation handling
   - Speaker embedding analysis

4. **Intelligent Alignment** (`core/pipeline.py`)
   - Text-to-speaker mapping
   - Temporal overlap resolution
   - Confidence scoring

5. **Post-Processing** (`core/stitch.py`, `core/flag.py`)
   - Sentence reconstruction
   - Quality assurance flagging
   - Anomaly detection

### Web Interface Features

- **Real-time Video Synchronization**: Frame-accurate playback control
- **Interactive Text Editing**: Live transcript modification
- **Speaker Management**: Dynamic speaker identification and renaming
- **Quality Review**: Flagged segments for human verification
- **Export Capabilities**: Multiple output formats for clinical use

## ğŸ› ï¸ API Endpoints

### Core API Routes

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/temp/chunks` | List available transcript chunks |
| `GET` | `/api/temp/chunk/{filename}` | Retrieve specific chunk data |
| `POST` | `/api/temp/save` | Save edited transcript |
| `GET` | `/api/videos` | List available video files |

### Data Flow

```
Audio/Video Input â†’ Splitting â†’ Whisper â†’ Pyannote â†’ Alignment â†’ Stitching â†’ Flagging â†’ Human Review
```

## ğŸ”¬ Clinical Use Case

### ASD Diagnostic Interview Processing

The system is specifically designed for processing clinical conversations between:
- **Clinicians** (é†«å¸«): Medical professionals conducting assessments
- **Parents/Caregivers** (å®¶é•·): Providing developmental history
- **Children** (å…’ç«¥): Direct interaction and behavioral observation

### Key Clinical Features

- **Medical Terminology Recognition**: Optimized for clinical vocabulary
- **Behavioral Annotation**: Flags for attention, social interaction patterns
- **Compliance Standards**: HIPAA-compliant local processing
- **Quality Assurance**: Multi-level review system for accuracy

## ğŸš€ Development

### Adding New Features

1. **Backend Extensions**: Add new processing modules in `/backend/core/`
2. **Frontend Components**: Extend React components in `/frontend/src/`
3. **API Routes**: Add endpoints in `/backend/main.py`

### Testing

```bash
# Backend tests
cd backend
python -m pytest tests/

# Frontend tests
cd frontend
npm test
```

### Performance Optimization

- **GPU Memory Management**: Automatic VRAM cleanup between processing stages
- **Batch Processing**: Configurable chunk sizes for large files
- **Caching**: Model caching for faster subsequent runs

## ğŸ“Š System Requirements

### Minimum Requirements
- **GPU**: NVIDIA GTX 1660 (6GB VRAM)
- **RAM**: 16GB system memory
- **Storage**: 50GB for models and data
- **CPU**: 8-core processor

### Recommended Requirements
- **GPU**: NVIDIA RTX 4070+ (12GB+ VRAM)
- **RAM**: 32GB system memory
- **Storage**: 100GB NVMe SSD
- **CPU**: 12+ core processor

## ğŸ”’ Security & Privacy

- **Local Processing**: All audio processing occurs locally
- **No Cloud Dependencies**: Complete offline operation capability
- **Data Encryption**: Optional encryption for sensitive clinical data
- **Access Control**: Role-based access for clinical teams

## ğŸ“ License

This project is designed for clinical research and diagnostic applications. Please ensure compliance with local healthcare data regulations.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Submit a pull request

## ğŸ“ Support

For technical support or clinical implementation questions, please refer to the documentation or create an issue in the repository.

---

**Note**: This system requires appropriate clinical validation and should be used as a supportive tool in conjunction with professional medical judgment.