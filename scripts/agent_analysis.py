import json
import torch
import os
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()

# ==========================================
# 1. è¨­å®šèˆ‡è·¯å¾‘
# ==========================================
TEXT_JSON = "data/text/full_whisper_transcript_with_timestamps.json"
SPEAKER_JSON = "data/text/stage1_whisperx_aligned.json"
OUTPUT_FULL_REPORT = "data/report/final_full_analysis.json"
LOCAL_MODEL_PATH = "D:/hf_models/Llama-3.1-8B-Instruct"

# ==========================================
# 2. è¬èƒ½åˆä½µå·¥å…· (å·²ä¿®æ­£æ ¼å¼å•é¡Œ)
# ==========================================
def merge_transcripts(text_data, speaker_data):
    print("ğŸ”„ æ­£åœ¨åˆä½µ Whisper æ–‡å­—èˆ‡ Pyannote èªè€…è³‡è¨Š...")
    
    # 1. è™•ç†è¼¸å…¥æ ¼å¼å·®ç•° (List vs Dict)
    if isinstance(text_data, list):
        segments = text_data
    elif isinstance(text_data, dict):
        segments = text_data.get('segments', []) or text_data.get('chunks', [])
    else:
        raise ValueError("ç„¡æ³•è­˜åˆ¥æ–‡å­—æª”çš„ JSON çµæ§‹")

    merged = []
    
    for seg in segments:
        # 2. è™•ç†æ™‚é–“æˆ³æ ¼å¼å·®ç•°
        # ä½ çš„æ ¼å¼æ˜¯: "timestamp": [1.0, 3.0]
        if 'timestamp' in seg and isinstance(seg['timestamp'], list):
            if seg['timestamp'] is None: continue # è·³éç„¡æ•ˆç‰‡æ®µ
            t_start = seg['timestamp'][0]
            t_end = seg['timestamp'][1]
        # æ¨™æº–æ ¼å¼æ˜¯: "start": 1.0, "end": 3.0
        elif 'start' in seg and 'end' in seg:
            t_start = seg['start']
            t_end = seg['end']
        else:
            continue # ç„¡æ³•å–å¾—æ™‚é–“ï¼Œè·³é

        text = seg.get('text', '').strip()
        if not text: continue

        # 3. èªè€…åŒ¹é…é‚è¼¯ (ä¸è®Š)
        best_speaker = "Unknown"
        max_overlap = 0
        
        for spk_seg in speaker_data:
            s_start = spk_seg['start']
            s_end = spk_seg['end']
            
            # è¨ˆç®—é‡ç–Š
            overlap_start = max(t_start, s_start)
            overlap_end = min(t_end, s_end)
            overlap = max(0, overlap_end - overlap_start)
            
            if overlap > max_overlap:
                max_overlap = overlap
                best_speaker = spk_seg.get('speaker', 'Unknown')
        
        merged.append({
            "start": t_start,
            "end": t_end,
            "speaker": best_speaker,
            "text": text
        })
    return merged

# ==========================================
# 3. åˆå§‹åŒ– Llama-3 (4-bit)
# ==========================================
print("ğŸ§  [Agent] åˆå§‹åŒ– Llama-3.1 (4-bit Mode)...")

bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_use_double_quant=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16
)

try:
    tokenizer = AutoTokenizer.from_pretrained(LOCAL_MODEL_PATH)
    if tokenizer.pad_token_id is None: tokenizer.pad_token_id = tokenizer.eos_token_id
    
    model = AutoModelForCausalLM.from_pretrained(
        LOCAL_MODEL_PATH,
        quantization_config=bnb_config,
        device_map="auto",
        local_files_only=True
    )
    
    agent_pipe = pipeline(
        "text-generation",
        model=model,
        tokenizer=tokenizer,
        max_new_tokens=2000, 
        temperature=0.1,
        return_full_text=False
    )
except Exception as e:
    print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    exit()

# ==========================================
# 4. åŸ·è¡Œæµç¨‹
# ==========================================
if not os.path.exists(TEXT_JSON) or not os.path.exists(SPEAKER_JSON):
    print("âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”æ¡ˆ")
    exit()

with open(TEXT_JSON, 'r', encoding='utf-8') as f:
    text_data = json.load(f)

with open(SPEAKER_JSON, 'r', encoding='utf-8') as f:
    speaker_data = json.load(f)

# åˆä½µ
full_dialogue = merge_transcripts(text_data, speaker_data)
print(f"âœ… åˆä½µå®Œæˆï¼Œå…± {len(full_dialogue)} å¥å°è©±ã€‚")

# ==========================================
# 5. Layer 1: è§’è‰²é–å®š
# ==========================================
print("\nğŸ•µï¸ [Layer 1] åˆ¤æ–·è§’è‰² (Therapist vs Child)...")
preview_lines = []
# å–å‰ 25 å¥ï¼Œè®“æ¨¡å‹æœ‰è¶³å¤ ä¸Šä¸‹æ–‡åˆ¤æ–·
for item in full_dialogue[:25]:
    preview_lines.append(f"{item['speaker']}: {item['text']}")
preview_text = "\n".join(preview_lines)

role_prompt = [
    {"role": "system", "content": "ä½ æ˜¯å…’ç«¥è·èƒ½æ²»ç™‚å°ˆå®¶ã€‚è«‹æ ¹æ“šå°è©±åˆ¤æ–· SPEAKER_00 å’Œ SPEAKER_01 èª°æ˜¯ 'Therapist' (æ²»ç™‚å¸«)ï¼Œèª°æ˜¯ 'Child' (å…’ç«¥)ã€‚"},
    {"role": "user", "content": f"å°è©±ç‰‡æ®µï¼š\n{preview_text}\n\nè«‹ç›´æ¥è¼¸å‡º JSON æ ¼å¼ï¼Œä¸è¦è§£é‡‹ã€‚ä¾‹å¦‚ï¼š{{\"SPEAKER_00\": \"Therapist\", \"SPEAKER_01\": \"Child\"}}"}
]

role_map = {"SPEAKER_00": "Unknown", "SPEAKER_01": "Unknown"}
try:
    role_result = agent_pipe(role_prompt)[0]['generated_text']
    print(f"ğŸ¤– è§’è‰²åˆ¤æ–·è¼¸å‡º: {role_result.strip()}")
    json_match = re.search(r"\{.*\}", role_result, re.DOTALL)
    if json_match:
        role_map = json.loads(json_match.group(0))
        print(f"âœ… é–å®šè§’è‰²: {role_map}")
except:
    print("âš ï¸ è§’è‰²åˆ¤æ–·è§£æå¤±æ•—ï¼Œå°‡ä½¿ç”¨ Unknown")

# ==========================================
# 6. Layer 2: æ‰¹æ¬¡åˆ†æ (åªè·‘å‰ 2 å€‹æ¸¬è©¦)
# ==========================================
print("\nğŸ“‹ [Layer 2] é–‹å§‹å…¨é‡è¡Œç‚ºåˆ†æ (æ¸¬è©¦æ¨¡å¼: åªè·‘å‰ 2 æ‰¹)...")

final_report = []
CHUNK_SIZE = 50 
# åˆ‡åˆ† Chunks
all_chunks = [full_dialogue[i:i + CHUNK_SIZE] for i in range(0, len(full_dialogue), CHUNK_SIZE)]

# ğŸ›‘ã€ä¿®æ”¹é» 1ã€‘åªå–å‰ 2 å€‹ chunk ä¾†è·‘ï¼Œç¯€çœæ™‚é–“
test_chunks = all_chunks[:2] 

print(f"ğŸ“Š ç¸½å…± {len(all_chunks)} å€‹æ‰¹æ¬¡ï¼Œç›®å‰åªåŸ·è¡Œå‰ {len(test_chunks)} å€‹é€²è¡Œæ¸¬è©¦...")

for idx, chunk in enumerate(tqdm(test_chunks)):
    chunk_text = ""
    for item in chunk:
        spk = item['speaker']
        role = role_map.get(spk, spk)
        t_str = f"{int(item['start']//60):02d}:{int(item['start']%60):02d}"
        chunk_text += f"[{t_str}] {role}: {item['text']}\n"
    
    prompt_content = f"""
    ä»»å‹™ï¼šåˆ†æä»¥ä¸‹è‡ªé–‰ç—‡æ²»ç™‚å°è©±ã€‚
    
    è«‹è¼¸å‡º JSON Listï¼Œæ ¼å¼ï¼š[{{"time": "MM:SS", "role": "Child", "text": "...", "behavior": "..."}}]
    
    æ¨™è¨˜è¦å‰‡ï¼š
    1. **Echolalia (ä»¿èªª)**ï¼šChild é‡è¤‡ Therapist çš„è©±ã€‚
    2. **Verbal_Refusal (æ‹’çµ•)**ï¼šChild èªª "ä¸è¦"ã€"ä¸æƒ³"ã€‚
    3. **Correction (ASRä¿®æ­£)**ï¼šä¿®æ­£éŒ¯å­—ã€‚

    å°è©±å…§å®¹ï¼š
    {chunk_text}
    """
    
    msgs = [{"role": "user", "content": prompt_content}]
    
    try:
        res = agent_pipe(msgs)[0]['generated_text']
        
        # ğŸ›‘ã€ä¿®æ”¹é» 2ã€‘å¢å¼·è§£æé‚è¼¯
        # å˜—è©¦å°‹æ‰¾æœ€å¤–å±¤çš„ [ ... ]
        list_match = re.search(r"\[.*\]", res, re.DOTALL)
        
        if list_match:
            try:
                # é€™è£¡æœ‰æ™‚å€™æ¨¡å‹æœƒè¼¸å‡º [JSON] èªªæ˜æ–‡å­—ï¼Œå°è‡´è§£æå¤±æ•—
                # æˆ‘å€‘ç”¨è¼ƒå¯¬é¬†çš„æ–¹å¼å˜—è©¦è§£æ
                json_str = list_match.group(0)
                parsed = json.loads(json_str)
                final_report.extend(parsed)
            except json.JSONDecodeError:
                # å¦‚æœ JSON æ ¼å¼å£æ‰ï¼Œå˜—è©¦ä¿®å¾©æˆ–åƒ…ä¿å­˜åŸå§‹æ–‡å­—
                print(f"âš ï¸ Batch {idx} JSON æ ¼å¼æœ‰èª¤ï¼Œå·²ä¿å­˜åŸå§‹æ–‡å­—ã€‚")
                final_report.append({"batch_id": idx, "error": "Invalid JSON", "raw_output": res})
        else:
            final_report.append({"batch_id": idx, "error": "No JSON found", "raw_output": res})
            
    except Exception as e:
        print(f"âš ï¸ Batch {idx} ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}")

# ==========================================
# 7. å­˜æª”
# ==========================================
os.makedirs(os.path.dirname(OUTPUT_FULL_REPORT), exist_ok=True)
with open(OUTPUT_FULL_REPORT, 'w', encoding='utf-8') as f:
    json.dump(final_report, f, ensure_ascii=False, indent=4)

print(f"\nğŸ‰ æ¸¬è©¦å®Œæˆï¼è«‹æŸ¥çœ‹å ±å‘Š: {OUTPUT_FULL_REPORT}")
print("ç¢ºèªæ ¼å¼æ²’å•é¡Œå¾Œï¼Œå†æŠŠ [:2] æ‹¿æ‰è·‘å…¨é‡ã€‚")