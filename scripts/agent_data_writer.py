import json
import torch
import os
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()

# ==========================================
# 1. è¨­å®šèˆ‡è·¯å¾‘
# ==========================================
TEXT_JSON = "data/text/full_whisper_transcript_with_timestamps.json"
SPEAKER_JSON = "data/text/stage1_whisperx_aligned.json"
OUTPUT_SCRIPT = "data/db/formatted_script.json" # é€™æ˜¯ Agent "å¯«å…¥" çš„çµæœ
LOCAL_MODEL_PATH = "D:/hf_models/Llama-3.1-8B-Instruct"

TEST_MODE = False # True: åªè·‘å‰ 3 å€‹ Batch (å¿«é€Ÿæ¸¬è©¦)

# ==========================================
# 2. å®šç¾©ã€Œå¯«å…¥å·¥å…·ã€ (The Writer Tool)
# ==========================================
class ScriptWriter:
    def __init__(self, raw_source):
        self.raw_source = raw_source # åŸå§‹é«’è³‡æ–™ï¼Œç”¨ä¾†æŸ¥æ™‚é–“æˆ³è¨˜
        self.clean_script = []       # é€™æ˜¯ Agent è¦å¯«å…¥çš„ä¹¾æ·¨åŠ‡æœ¬
        self.write_count = 0

    def tool_write_line(self, original_id, role, text):
        """
        Agent å‘¼å«æ­¤å·¥å…·ä¾†ã€Œå¯«å…¥ã€ä¸€è¡Œä¹¾æ·¨çš„è³‡æ–™ã€‚
        Agent ä¸éœ€è¦ç®¡æ™‚é–“æˆ³è¨˜ï¼ŒPython æœƒè‡ªå‹•å¾åŸå§‹è³‡æ–™å»æŠ“å°æ‡‰çš„æ™‚é–“ã€‚
        """
        # 1. é©—è­‰ ID æ˜¯å¦åˆæ³•
        if original_id < 0 or original_id >= len(self.raw_source):
            print(f"âš ï¸ [Tool Error] Invalid ID: {original_id}")
            return

        # 2. ç²å–åŸå§‹ç‰©ç†è³‡è¨Š (æ™‚é–“æˆ³)
        raw_item = self.raw_source[original_id]
        
        # 3. è¦ç¯„åŒ–è§’è‰²åç¨± (Schema Validation)
        clean_role = "Unknown"
        role_lower = role.lower()
        if "child" in role_lower: clean_role = "Child"
        elif "therapist" in role_lower or "adult" in role_lower: clean_role = "Therapist"
        
        # 4. å»ºæ§‹ä¹¾æ·¨ç´€éŒ„
        record = {
            "id": self.write_count,       # æ–°çš„æµæ°´è™Ÿ
            "source_id": original_id,     # æº¯æº ID (æ–¹ä¾¿é™¤éŒ¯)
            "time_start": raw_item['start'],
            "time_end": raw_item['end'],
            "role": clean_role,           # Agent åˆ¤æ–·çš„
            "text": text.strip()          # Agent ä¿®æ­£çš„
        }
        
        # 5. å¯«å…¥è³‡æ–™åº«
        self.clean_script.append(record)
        self.write_count += 1
        # print(f"  -> Wrote: [{clean_role}] {text}") # Debug ç”¨

# ==========================================
# 3. è¬èƒ½åˆä½µé‚è¼¯ (ç‰©ç†å±¤)
# ==========================================
def merge_transcripts(text_data, speaker_data):
    print("ğŸ”„ [System] Merging raw data streams...")
    if isinstance(text_data, list): segments = text_data
    elif isinstance(text_data, dict): segments = text_data.get('segments', [])
    else: segments = []

    merged = []
    for seg in segments:
        t_start, t_end = 0.0, 0.0
        if 'timestamp' in seg and isinstance(seg['timestamp'], list) and seg['timestamp']:
            t_start, t_end = seg['timestamp']
        elif 'start' in seg:
            t_start, t_end = seg['start'], seg['end']
        else: continue

        text = seg.get('text', '').strip()
        if not text: continue

        # ç°¡å–®èªè€…åŒ¹é…
        best_speaker = "Unknown"
        max_overlap = 0
        for spk_seg in speaker_data:
            s_start, s_end = spk_seg['start'], spk_seg['end']
            overlap = max(0, min(t_end, s_end) - max(t_start, s_start))
            if overlap > max_overlap:
                max_overlap = overlap
                best_speaker = spk_seg.get('speaker', 'Unknown')
        
        merged.append({"start": t_start, "end": t_end, "speaker": best_speaker, "text": text})
    
    print(f"âœ… Merged {len(merged)} raw lines.")
    return merged

# ==========================================
# 4. åˆå§‹åŒ–æ¨¡å‹
# ==========================================
print("ğŸ§  [Writer Agent] Initializing Llama-3.1...")
bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type="nf4", bnb_4bit_compute_dtype=torch.float16)
tokenizer = AutoTokenizer.from_pretrained(LOCAL_MODEL_PATH)
if tokenizer.pad_token_id is None: tokenizer.pad_token_id = tokenizer.eos_token_id
model = AutoModelForCausalLM.from_pretrained(LOCAL_MODEL_PATH, quantization_config=bnb_config, device_map="auto", local_files_only=True)
pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=512, temperature=0.1)

# ==========================================
# 5. Agent åŸ·è¡Œè¿´åœˆ (å·²ä¿®æ­£ List/String éŒ¯èª¤)
# ==========================================
def run_writer_agent():
    # Load Data
    with open(TEXT_JSON, 'r', encoding='utf-8') as f: t_data = json.load(f)
    with open(SPEAKER_JSON, 'r', encoding='utf-8') as f: s_data = json.load(f)
    
    raw_merged = merge_transcripts(t_data, s_data)
    
    # åˆå§‹åŒ–å¯«å…¥å™¨
    writer = ScriptWriter(raw_merged)
    
    # æ‰¹æ¬¡è™•ç†
    BATCH_SIZE = 5
    total_len = len(raw_merged)
    
    if TEST_MODE:
        run_range = range(0, min(15, total_len), BATCH_SIZE)
        print(f"ğŸš€ [æ¸¬è©¦æ¨¡å¼] Agent é–‹å§‹å·¥ä½œ (åªè™•ç†å‰ {min(15, total_len)} å¥)...")
    else:
        run_range = range(0, total_len, BATCH_SIZE)
        print(f"ğŸš€ [å…¨é‡æ¨¡å¼] Agent é–‹å§‹å·¥ä½œ (å…± {total_len} å¥)...")

    for i in tqdm(run_range):
        # A. æº–å‚™ Context
        batch_end = min(i + BATCH_SIZE, total_len)
        context_str = ""
        current_batch_ids = []
        
        for idx in range(i, batch_end):
            item = raw_merged[idx]
            context_str += f"ID: {idx} | Raw Speaker: {item['speaker']} | Raw Text: \"{item['text']}\"\n"
            current_batch_ids.append(idx)
        
        # B. Prompt (Agent æ€è€ƒ) - å·²åŠ å…¥ç¹é«”ä¸­æ–‡å¼·åˆ¶æŒ‡ä»¤
        prompt = f"""
        ä½ æ˜¯ä¸€å€‹ä¾†è‡ªå°ç£çš„è‡¨åºŠè½‰éŒ„ Agent (Taiwan Clinical Transcriber)ã€‚
        ä½ çš„ä»»å‹™æ˜¯å°‡åŸå§‹çš„ ASR è³‡æ–™è½‰æ›ç‚ºä¹¾æ·¨çš„åŠ‡æœ¬ã€‚
        
        ã€ä»»å‹™ã€‘
        1. åˆ¤æ–·çœŸå¯¦è§’è‰² (Therapist æˆ– Child)ã€‚
        2. ä¿®æ­£éŒ¯å­— (Text Normalization)ã€‚
        
        ã€é‡è¦è¦å‰‡ã€‘
        - **å¿…é ˆä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡ (Traditional Chinese)**ã€‚
        - ä¿®æ­£ç”¨èªéœ€ç¬¦åˆå°ç£é†«ç™‚æƒ…å¢ƒ (ä¾‹å¦‚ï¼šä¸è¦ä½¿ç”¨ä¸­åœ‹ç”¨èª)ã€‚
        
        ã€å·¥å…·æŒ‡ä»¤ã€‘
        ä½¿ç”¨ä»¥ä¸‹æ ¼å¼å¯«å…¥æ¯ä¸€è¡Œï¼š
        WRITE | ID | Role | Clean Text
        
        - ID: å¿…é ˆå°æ‡‰è¼¸å…¥çš„ ID
        - Role: åªå…è¨± 'Child' æˆ– 'Therapist'
        - Clean Text: ä¿®æ­£å¾Œçš„**ç¹é«”ä¸­æ–‡**å…§å®¹
        
        ã€è¼¸å…¥ Raw Dataã€‘
        {context_str}
        
        ã€ä½ çš„æŒ‡ä»¤è¼¸å‡ºã€‘
        """
        
        msgs = [{"role": "user", "content": prompt}]
        
        try:
            # C. ç”ŸæˆæŒ‡ä»¤
            outputs = pipe(msgs)
            raw_res = outputs[0]['generated_text']
            
            # ğŸ›‘ã€ä¿®æ­£é»ã€‘åˆ¤æ–·å›å‚³é¡å‹
            if isinstance(raw_res, list):
                # å¦‚æœæ˜¯ Listï¼Œé€šå¸¸æœ€å¾Œä¸€ç­†æ‰æ˜¯ AI çš„å›è¦†
                res = raw_res[-1]['content']
            elif isinstance(raw_res, dict):
                res = raw_res.get('content', '')
            else:
                # å¦‚æœæ˜¯å­—ä¸²ï¼Œç›´æ¥ç”¨
                res = str(raw_res)
            
            # D. è§£æèˆ‡åŸ·è¡Œ
            lines = res.strip().split('\n')
            for line in lines:
                if "WRITE |" in line:
                    parts = line.split('|')
                    if len(parts) >= 4:
                        try:
                            p_id = int(parts[1].strip())
                            p_role = parts[2].strip()
                            p_text = parts[3].strip()
                            
                            if p_id in current_batch_ids:
                                writer.tool_write_line(p_id, p_role, p_text)
                        except ValueError:
                            pass # å¿½ç•¥è§£æå¤±æ•—çš„è¡Œ
                            
        except Exception as e:
            print(f"âŒ Batch Error at index {i}: {e}")
            # å°å‡ºé€™è¡Œä¾†é™¤éŒ¯ï¼Œçœ‹çœ‹æ¨¡å‹åˆ°åº•å›å‚³äº†ä»€éº¼çµæ§‹
            # print(f"DEBUG info: {type(outputs[0]['generated_text'])}") 

    # ==========================================
    # 6. å­˜æª”
    # ==========================================
    print("\n" + "="*30)
    print(f"ğŸ“Š å¯«å…¥å®Œæˆï¼å…±ç”¢å‡º {writer.write_count} è¡Œä¹¾æ·¨åŠ‡æœ¬ã€‚")
    
    os.makedirs(os.path.dirname(OUTPUT_SCRIPT), exist_ok=True)
    with open(OUTPUT_SCRIPT, 'w', encoding='utf-8') as f:
        json.dump(writer.clean_script, f, ensure_ascii=False, indent=4)
        
    print(f"ğŸ’¾ æª”æ¡ˆå·²å„²å­˜: {OUTPUT_SCRIPT}")
    if TEST_MODE:
        print("ğŸ’¡ æ¸¬è©¦å®Œæˆã€‚è«‹å°‡ç¨‹å¼ç¢¼ä¸­çš„ `TEST_MODE = False` åŸ·è¡Œå…¨é‡ã€‚")

if __name__ == "__main__":
    run_writer_agent()