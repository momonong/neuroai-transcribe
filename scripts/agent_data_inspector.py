import json
import torch
import os
import re
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, BitsAndBytesConfig
from torch.utils.data import Dataset
from tqdm import tqdm
from dotenv import load_dotenv

load_dotenv()

# ==========================================
# 1. è¨­å®š
# ==========================================
INPUT_SCRIPT = "data/db/formatted_script.json"
OUTPUT_WEB_READY = "data/db/final_web_ready_script.json"
LOCAL_MODEL_PATH = os.getenv("LLAMA_MODEL_PATH", "D:/hf_models/Llama-3.1-8B-Instruct")

# âš¡ Batch Size: 32 (5090 é¡¯å¡å»ºè­°å€¼)
BATCH_SIZE = 32

# ğŸ§ª æ¸¬è©¦ç­†æ•¸ï¼šè¨­ç‚º 0 æˆ– None ä»£è¡¨è·‘å…¨é‡
# å¦‚æœåªæƒ³è·‘å‰ 100 å¥æ¸¬è©¦ï¼Œå°±è¨­ 100
TEST_SIZE = 0 

# ==========================================
# 2. å®šç¾© Agent çš„ç’°å¢ƒèˆ‡å·¥å…·
# ==========================================
class ClinicalInspector:
    def __init__(self, script_data):
        self.script = script_data
        for item in self.script:
            if 'flags' not in item: item['flags'] = []
            if 'review_status' not in item: item['review_status'] = 'pending'
        self.action_log = []

    def tool_add_flag(self, idx, flag_type, severity, note):
        target_item = next((item for item in self.script if item['id'] == idx), None)
        if target_item:
            # é¿å…é‡è¤‡æ¨™è¨˜åŒä¸€ç¨®é¡å‹
            for f in target_item['flags']:
                if f['type'] == flag_type: return

            flag_entry = {
                "type": flag_type,
                "severity": severity,
                "note": note,
                "created_by": "Layer2_Agent"
            }
            target_item['flags'].append(flag_entry)
            
            # åªè¦æœ‰ High Severity å°±äº®ç´…ç‡ˆ
            if severity == "High":
                target_item['review_status'] = "needs_review"
            
            self.action_log.append(f"Action: Flagged ID {idx} as {flag_type}")

# ==========================================
# 3. å®šç¾©è³‡æ–™é›† (åŒ…å«é‡è¤‡åµæ¸¬)
# ==========================================
# ==========================================
# 3. å®šç¾©è³‡æ–™é›† (ä¿®æ­£ç‰ˆï¼šé‡å°ã€Œå¥‡æ€ªåè©çµ„åˆã€)
# ==========================================
class InspectorDataset(Dataset):
    def __init__(self, script_data, tokenizer):
        self.prompts = []
        self.ids = [] 
        
        print("âš¡ [System] çµ„è£ Prompts (Naturalness Check)...")
        
        for i in range(len(script_data)):
            curr = script_data[i]
            prev = script_data[i-1] if i > 0 else {"role": "None", "text": ""}
            
            context_str = f"""
            [ä¸Šä¸€å¥] {prev['role']}: "{prev['text']}"
            [ç•¶å‰å¥] {curr['role']}: "{curr['text']}"
            """
            
            # ğŸ”¥ Prompt é‡é»ä¿®æ­£ï¼šæ•™å®ƒåˆ†è¾¨ã€Œä¸è‡ªç„¶ã€
            prompt = f"""
            ä½ æ˜¯ä¸€å€‹ ASR (èªéŸ³è½‰æ–‡å­—) å“è³ªæª¢æŸ¥å“¡ã€‚è«‹æª¢æŸ¥ [ç•¶å‰å¥] æ˜¯å¦ç‚º **ç„¡æ•ˆçš„è½‰éŒ„çµæœ**ã€‚
            
            ã€ä½ çš„æ ¸å¿ƒä»»å‹™ã€‘
            åˆ¤æ–·é€™å¥è©±æ˜¯ã€Œäººé¡å£èª (åŒ…å«å°å­©)ã€é‚„æ˜¯ã€Œæ©Ÿå™¨ç”¢ç”Ÿçš„äº‚ç¢¼ã€ã€‚
            
            ã€åˆ¤æ–·æ¨™æº–ã€‘
            1. **PASS (äººé¡å£èª)**ï¼š
               - **ç°¡å–®çŸ­å¥**ï¼šå¦‚ "å¥½"ã€"å°"ã€"è»Šè»Š"ã€"å†°æ·‡æ·‹" (å³ä½¿å¾ˆçŸ­ï¼Œåªè¦æ˜¯å¸¸è¦‹å£èªè©å½™ï¼ŒPASS)ã€‚
               - **é‚è¼¯è·³èº**ï¼šå°å­©çªç„¶èªª "æˆ‘è¦åƒç³–"ï¼Œå³ä½¿è·Ÿä¸Šä¸€å¥ç„¡é—œï¼Œåªè¦å¥å­æœ¬èº«é€šé †ï¼ŒPASSã€‚
               - **èªæ³•ç ´ç¢**ï¼šå¦‚ "é‚£å€‹...æˆ‘è¦...é‚£å€‹" (PASS)ã€‚
            
            2. **FLAG (æ©Ÿå™¨éŒ¯èª¤)**ï¼š
               - **å–®è©æ²™æ‹‰ (Word Salad)**ï¼šå¹¾å€‹ä¸ç›¸é—œçš„ä¸­æ–‡å­—ç¡¬æ¹Šåœ¨ä¸€èµ·ï¼Œå®Œå…¨ä¸é€šé †ã€‚
                 (ä¾‹å¦‚ï¼š"é›è…¿é‡å…ˆä¼¸å”‡"ã€"å¤©æ°£æ›¸æœ¬é£›æ©Ÿ") -> **FLAG**
               - **ç„¡é™è¿´åœˆ**ï¼šé‡è¤‡å­—å…ƒè¶…é 3 æ¬¡ä»¥ä¸Šã€‚
                 (ä¾‹å¦‚ï¼š"å•Šå•Šå•Šå•Šå•Šå•Š"ã€"æ½‘æ°´æ½‘æ°´æ½‘æ°´æ½‘æ°´") -> **FLAG**
               - **éäººé¡èªè¨€**ï¼šäº‚ç¢¼ç¬¦è™Ÿ (å¦‚ "???", "xkq") -> **FLAG**
            
            ã€å·¥å…·æŒ‡ä»¤ã€‘
            PASS
            FLAG | SEMANTIC_ERROR | High | <å…·é«”èªªæ˜ç‚ºä»€éº¼é€™ä¸åƒäººè©±>
            
            ã€è¼¸å…¥è³‡æ–™ã€‘
            {context_str}
            
            ã€ä½ çš„æŒ‡ä»¤ã€‘
            """
            
            msgs = [{"role": "user", "content": prompt}]
            full_prompt_str = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)
            self.prompts.append(full_prompt_str)
            self.ids.append(curr['id'])

    def __len__(self):
        return len(self.prompts)

    def __getitem__(self, idx):
        return self.prompts[idx]

# ==========================================
# 4. åˆå§‹åŒ–æ¨¡å‹
# ==========================================
print("ğŸ§  [Layer 2 Agent] Initializing...")
bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type="nf4", bnb_4bit_compute_dtype=torch.float16)

tokenizer = AutoTokenizer.from_pretrained(LOCAL_MODEL_PATH)
tokenizer.padding_side = 'left' 
if tokenizer.pad_token_id is None: tokenizer.pad_token_id = tokenizer.eos_token_id

model = AutoModelForCausalLM.from_pretrained(LOCAL_MODEL_PATH, quantization_config=bnb_config, device_map="auto", local_files_only=True)

pipe = pipeline("text-generation", model=model, tokenizer=tokenizer, max_new_tokens=128, temperature=0.1, batch_size=BATCH_SIZE, return_full_text=False)

# ==========================================
# 5. ä¸»æµç¨‹
# ==========================================
def run_batch_agent():
    if not os.path.exists(INPUT_SCRIPT):
        print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æª”: {INPUT_SCRIPT}")
        return
    
    with open(INPUT_SCRIPT, 'r', encoding='utf-8') as f:
        full_data = json.load(f)
        
    # ğŸ§ª è™•ç†æ¸¬è©¦æ¨¡å¼
    if TEST_SIZE > 0:
        script_data = full_data[:TEST_SIZE]
        print(f"âš ï¸ TEST MODE: åƒ…è™•ç†å‰ {len(script_data)} ç­†è³‡æ–™ã€‚")
    else:
        script_data = full_data
        print(f"ğŸš€ FULL MODE: è™•ç†å…¨é‡ {len(script_data)} ç­†è³‡æ–™ã€‚")

    inspector = ClinicalInspector(script_data)
    dataset = InspectorDataset(script_data, tokenizer)
    
    print(f"ğŸš€ Layer 2 Agent å•Ÿå‹• (Batch Size={BATCH_SIZE})...")
    
    results_iterator = pipe(dataset, batch_size=BATCH_SIZE)
    
    # 3. è§£æçµæœ
    for i, outputs in enumerate(tqdm(results_iterator, total=len(dataset))):
        current_id = dataset.ids[i]
        
        raw_res = outputs[0]['generated_text'] if isinstance(outputs, list) else outputs['generated_text']
        res = str(raw_res)
        
        # è§£ææŒ‡ä»¤
        lines = res.strip().split('\n')
        for line in lines:
            if "æŒ‡ä»¤:" in line or "FLAG |" in line:
                clean_line = line.replace("æŒ‡ä»¤:", "").strip()
                
                if "FLAG |" in clean_line:
                    parts = clean_line.split('|')
                    if len(parts) >= 4:
                        f_type = parts[1].strip()
                        f_sev = parts[2].strip()
                        f_note = parts[3].strip()
                        
                        # Python é¡å¤–é˜²å‘†ï¼šé†«ç”Ÿèªªè©±æˆ‘å€‘ä¸æ¨™è¨˜ (é™¤éä½ éœ€è¦æª¢æŸ¥é†«ç”Ÿçš„é‡è¤‡è©±)
                        # item_role = next((x['role'] for x in script_data if x['id'] == current_id), "Unknown")
                        # if item_role == "Therapist": continue 

                        inspector.tool_add_flag(current_id, f_type, f_sev, f_note)

    # ==========================================
    # 6. è¼¸å‡ºèˆ‡å­˜æª” (ä¿®æ­£è™•)
    # ==========================================
    print("\n" + "="*30)
    print(f"ğŸ“Š æª¢æŸ¥å®Œæˆï¼")
    
    stats = {}
    for item in script_data:
        for f in item['flags']:
            stats[f['type']] = stats.get(f['type'], 0) + 1
    print(f"ğŸ“ˆ æ¨™è¨˜çµ±è¨ˆ: {stats}")
    
    # ğŸ’¾ å„²å­˜æª”æ¡ˆ
    os.makedirs(os.path.dirname(OUTPUT_WEB_READY), exist_ok=True)
    with open(OUTPUT_WEB_READY, 'w', encoding='utf-8') as f:
        json.dump(script_data, f, ensure_ascii=False, indent=4)
        
    print(f"ğŸ’¾ è³‡æ–™å·²æˆåŠŸå„²å­˜è‡³: {OUTPUT_WEB_READY}")
    
    # å°å‡ºç¯„ä¾‹
    print("\nğŸ” è¢«æ¨™è¨˜çš„å¥å­ç¯„ä¾‹:")
    count = 0
    for item in script_data:
        if item['flags']:
            print(f"ID {item['id']} [{item['role']}]: {item['text']}")
            for f in item['flags']:
                print(f"   -> {f['type']} | {f['note']}")
            print("-" * 20)
            count += 1
            if count >= 10: break # åªå°å‰10å€‹é¿å…æ´—ç‰ˆ

if __name__ == "__main__":
    run_batch_agent()